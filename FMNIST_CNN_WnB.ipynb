{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvnananth/rasmitha/blob/main/FMNIST_CNN_WnB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ll7rTiy1l-D"
      },
      "outputs": [],
      "source": [
        "# Step 0: Install WandB if not installed\n",
        "!pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Imports\n",
        "import os\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "hFyATtZn1pkz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Download Fashion-MNIST data (gzipped)\n",
        "!wget -N http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "!wget -N http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
        "!wget -N http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
        "!wget -N http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
        "DATA_PATH = \"/content\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfXT66ss16mS",
        "outputId": "c6f56666-ef16-4f1c-c1cb-d790abcf8e0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-30 05:35:38--  http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Resolving fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)... 52.219.170.176, 52.219.170.60, 52.219.170.20, ...\n",
            "Connecting to fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)|52.219.170.176|:80... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘train-images-idx3-ubyte.gz’ not modified on server. Omitting download.\n",
            "\n",
            "--2026-01-30 05:35:38--  http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Resolving fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)... 52.219.170.176, 52.219.170.60, 52.219.170.20, ...\n",
            "Connecting to fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)|52.219.170.176|:80... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘train-labels-idx1-ubyte.gz’ not modified on server. Omitting download.\n",
            "\n",
            "--2026-01-30 05:35:38--  http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Resolving fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)... 52.219.170.176, 52.219.170.60, 52.219.170.20, ...\n",
            "Connecting to fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)|52.219.170.176|:80... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘t10k-images-idx3-ubyte.gz’ not modified on server. Omitting download.\n",
            "\n",
            "--2026-01-30 05:35:38--  http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Resolving fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)... 52.219.170.176, 52.219.170.60, 52.219.170.20, ...\n",
            "Connecting to fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)|52.219.170.176|:80... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘t10k-labels-idx1-ubyte.gz’ not modified on server. Omitting download.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Loader function for MNIST IDX files\n",
        "def load_mnist(path, kind='train'):\n",
        "    FILE_MAP = {\n",
        "        'train': ('train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz'),\n",
        "        't10k': ('t10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz')\n",
        "    }\n",
        "\n",
        "    images_file, labels_file = FILE_MAP[kind]\n",
        "    images_path = os.path.join(path, images_file)\n",
        "    labels_path = os.path.join(path, labels_file)\n",
        "\n",
        "    # Load labels\n",
        "    with gzip.open(labels_path, 'rb') as f:\n",
        "        labels = np.frombuffer(f.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "    # Load images\n",
        "    with gzip.open(images_path, 'rb') as f:\n",
        "        images = np.frombuffer(f.read(), dtype=np.uint8, offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels\n"
      ],
      "metadata": {
        "id": "KQoi8B132GlM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load datasets\n",
        "images_train, labels_train = load_mnist(DATA_PATH, 'train')\n",
        "images_test, labels_test = load_mnist(DATA_PATH, 't10k')\n",
        "\n",
        "print(\"Train images:\", images_train.shape, \"Train labels:\", labels_train.shape)\n",
        "print(\"Test images:\", images_test.shape, \"Test labels:\", labels_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFla9Skb2Z4V",
        "outputId": "5da4feb0-1055-4ac3-f8a0-0ef679ccd3fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (60000, 784) Train labels: (60000,)\n",
            "Test images: (10000, 784) Test labels: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define PyTorch Dataset\n",
        "class FMNISTDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = torch.tensor(self.images[idx], dtype=torch.float32).view(1, 28, 28)\n",
        "        img =img / 255.0\n",
        "        lbl = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return img, lbl\n",
        "\n",
        "traindata = FMNISTDataset(images_train, labels_train)\n",
        "testdata = FMNISTDataset(images_test, labels_test)\n",
        "\n",
        "trainloader = DataLoader(traindata, batch_size=128, shuffle=True, num_workers = 2)\n",
        "testloader = DataLoader(testdata, batch_size=128, num_workers = 2)"
      ],
      "metadata": {
        "id": "v0C0RHDA2eJq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Define CNN\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(64, 10)\n",
        "        \"\"\"\n",
        "        Examples:\n",
        "        >>> # target output size of 5x7\n",
        "        >>> m = nn.AdaptiveAvgPool2d((5, 7))\n",
        "        >>> input = torch.randn(1, 64, 8, 9)\n",
        "        >>> output = m(input)\n",
        "        >>> # target output size of 7x7 (square)\n",
        "        >>> m = nn.AdaptiveAvgPool2d(7)\n",
        "        >>> input = torch.randn(1, 64, 10, 9)\n",
        "        >>> output = m(input)\n",
        "        >>> # target output size of 10x7\n",
        "        >>> m = nn.AdaptiveAvgPool2d((None, 7))\n",
        "        >>> input = torch.randn(1, 64, 10, 9)\n",
        "        >>> output = m(input)\n",
        "        \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.dropout(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "model = SimpleCNN()"
      ],
      "metadata": {
        "id": "XrZNfYSj2nZi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Initialize W&B\n",
        "wandb.init(\n",
        "    project=\"fmnist-tutorial\",\n",
        "    name=\"BetterCNN_CPU\",\n",
        "    config={\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"batch_size\": 128,\n",
        "        \"conv_channels\": [32, 64],\n",
        "        \"dataset\": \"Fashion-MNIST\",\n",
        "        \"kernel_size\": 3,\n",
        "        \"epochs\": 10,\n",
        "        \"normalization\": \"BatchNorm\"\n",
        "    }\n",
        ")\n",
        "wandb.watch(model, log=\"parameters\", log_freq=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Gy_Hf_sZ2r6m",
        "outputId": "f68c1107-bacb-4ac5-ac50-5ab560ca975d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using W&B in offline mode.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20260130_054815-730gy1pv</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Loss and optimizer\n",
        "#loss_fn = nn.NLLLoss()\n",
        "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=wandb.config.learning_rate, weight_decay =1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ],
      "metadata": {
        "id": "E7U4qfKG2yd4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Training loop with W&B logging\n",
        "epochs = wandb.config.epochs\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * data.size(0)\n",
        "\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "        total += target.size(0)\n",
        "\n",
        "        if batch_idx % 200 == 0:    #batches is 200\n",
        "            wandb.log({\"batch_loss\": loss.item(), \"epoch\": epoch})\n",
        "\n",
        "    avg_loss = running_loss / len(trainloader.dataset)\n",
        "    train_acc = 100 * correct / total\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    wandb.log({\"epoch_loss\": avg_loss, \"train_accuracy\": train_acc, \"epoch\": epoch})\n",
        "    print(f\"Epoch {epoch} average loss: {avg_loss:.4f} training loss: {train_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXqWf1ki23c2",
        "outputId": "beaa1f54-b116-4f4c-d718-cc2a756eab75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 average loss: 1.3868 training loss: 67.66%\n",
            "Epoch 1 average loss: 1.0721 training loss: 78.15%\n",
            "Epoch 2 average loss: 0.9966 training loss: 80.62%\n",
            "Epoch 3 average loss: 0.9508 training loss: 82.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Evaluate on test set\n",
        "def evaluate(model, dataloader, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in dataloader:\n",
        "            output = model(data)\n",
        "            loss = loss_fn(output, target)\n",
        "\n",
        "            total_loss += loss.item() * data.size(0)\n",
        "\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100.0 * correct / total\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "test_loss, test_acc = evaluate(model, testloader, loss_fn)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
        "wandb.log({\"test_loss\": test_loss, \"test_accuracy\": test_acc})"
      ],
      "metadata": {
        "id": "FfCG4jT53CHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Visualize some test images with predictions\n",
        "data_iter = iter(testloader)\n",
        "images, labels = next(data_iter)\n",
        "outputs = model(images)\n",
        "_, preds = torch.max(outputs, 1)\n",
        "\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "for idx in range(8):\n",
        "    ax = fig.add_subplot(2,4,idx+1)\n",
        "    ax.imshow(images[idx].cpu().squeeze(), cmap='gray')\n",
        "    ax.set_title(f\"Pred: {preds[idx].item()}\\nTrue: {labels[idx].item()}\")\n",
        "    ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Finish W&B run\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "rzr12sP03Fvb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}