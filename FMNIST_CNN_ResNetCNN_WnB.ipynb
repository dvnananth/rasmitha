{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvnananth/rasmitha/blob/main/FMNIST_CNN_ResNetCNN_WnB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yf-UFkkB63B8"
      },
      "outputs": [],
      "source": [
        "# Step 0: Install WandB if not installed\n",
        "!pip install -q wandb\n",
        "# Step 1: Imports\n",
        "import os\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 2: Download Fashion-MNIST\n",
        "!wget -N http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "!wget -N http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
        "!wget -N http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
        "!wget -N http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
        "\n",
        "DATA_PATH = \"/content\""
      ],
      "metadata": {
        "id": "FQTtO5kb67a-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaef9272-30ab-4c5c-96cb-dee206d32535"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-01 16:25:15--  http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Resolving fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)... 3.5.138.157, 3.5.138.233, 52.219.72.182, ...\n",
            "Connecting to fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)|3.5.138.157|:80... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘train-images-idx3-ubyte.gz’ not modified on server. Omitting download.\n",
            "\n",
            "--2026-02-01 16:25:15--  http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Resolving fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)... 3.5.138.157, 3.5.138.233, 52.219.72.182, ...\n",
            "Connecting to fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)|3.5.138.157|:80... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘train-labels-idx1-ubyte.gz’ not modified on server. Omitting download.\n",
            "\n",
            "--2026-02-01 16:25:16--  http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Resolving fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)... 3.5.138.157, 3.5.138.233, 52.219.72.182, ...\n",
            "Connecting to fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)|3.5.138.157|:80... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘t10k-images-idx3-ubyte.gz’ not modified on server. Omitting download.\n",
            "\n",
            "--2026-02-01 16:25:16--  http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Resolving fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)... 3.5.138.157, 3.5.138.233, 52.219.72.182, ...\n",
            "Connecting to fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)|3.5.138.157|:80... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘t10k-labels-idx1-ubyte.gz’ not modified on server. Omitting download.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 3: Load IDX files\n",
        "#IDX structure [magic number][num items][rows][cols][data...]\n",
        "\n",
        "#Loading Images & Labels\n",
        "def load_images(path):\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    return data.reshape(-1, 28, 28)\n",
        "def load_labels(path):\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    return labels\n",
        "\n",
        "# Training & Testing Data splitting\n",
        "images_train = load_images(DATA_PATH + \"/train-images-idx3-ubyte.gz\")\n",
        "labels_train = load_labels(DATA_PATH + \"/train-labels-idx1-ubyte.gz\")\n",
        "\n",
        "images_test = load_images(DATA_PATH + \"/t10k-images-idx3-ubyte.gz\")\n",
        "labels_test = load_labels(DATA_PATH + \"/t10k-labels-idx1-ubyte.gz\")\n",
        "\n",
        "#data checking 28828 size 60k images/ labels training and 10k testing\n",
        "print(images_train.shape)\n",
        "print(labels_train.shape)\n",
        "print(images_test.shape)\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n"
      ],
      "metadata": {
        "id": "0dAXMyyz7Gmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1586c17-cedb-4209-aa07-98776a7ed02b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FMNISTDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = torch.tensor(self.images[idx], dtype=torch.float32).unsqueeze(0)\n",
        "        img = img / 255.0              # normalization\n",
        "        lbl = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return img, lbl\n",
        "train_data = FMNISTDataset(images_train, labels_train)\n",
        "test_data  = FMNISTDataset(images_test, labels_test)\n",
        "\n",
        "trainloader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader  = DataLoader(test_data, batch_size=128, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "YxzpwISuv1p7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBoundBlock(nn.Module):\n",
        "    def __init__(self, channels, alpha=0.2):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channels, channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(channels)\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        return self.relu(x + self.alpha * out)\n"
      ],
      "metadata": {
        "id": "y_Oqv0fCu75J"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniResNetFMNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)     # 28 → 14\n",
        "        )\n",
        "\n",
        "        self.stage1 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),    # 14 → 7\n",
        "            ResBoundBlock(64),\n",
        "            ResBoundBlock(64)\n",
        "        )\n",
        "\n",
        "        self.stage2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            ResBoundBlock(128),\n",
        "            ResBoundBlock(128)\n",
        "        )\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.classifier(x)\n"
      ],
      "metadata": {
        "id": "G6vtIvn8u9bM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MiniResNetFMNIST()\n",
        "\n",
        "wandb.init(\n",
        "    project=\"fmnist-resnet\",\n",
        "    name=\"MiniResNet_ResBound\",\n",
        "    config={\n",
        "        \"model\": \"MiniResNet + ResBound\",\n",
        "        \"residual_alpha\": 0.2,\n",
        "        \"depth\": \"2+2 residual blocks\",\n",
        "        \"learning_rate\": 1e-3,\n",
        "        \"batch_size\": 128,\n",
        "        \"optimizer\": \"AdamW\",\n",
        "        \"scheduler\": \"StepLR\",\n",
        "        \"epochs\": 6\n",
        "    }\n",
        ")\n",
        "\n",
        "wandb.watch(model, log=\"parameters\", log_freq=500)\n"
      ],
      "metadata": {
        "id": "bcCqhf6uvDKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "fefc921e-5fe2-4b5b-9204-3348b8b1aeeb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20260201_162517-1ic6o4xw</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Loss and optimizer\n",
        "#loss_fn = nn.NLLLoss()\n",
        "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay =1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
      ],
      "metadata": {
        "id": "_Tk2hcT8vEhW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9A: Evaluation function (DEFINE FIRST)\n",
        "def evaluate(model, dataloader, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in dataloader:\n",
        "            output = model(data)\n",
        "            loss = loss_fn(output, target)\n",
        "\n",
        "            total_loss += loss.item() * data.size(0)\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100.0 * correct / total\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "W9jf1bs4vaUv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "epochs = wandb.config.epochs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * data.size(0)\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "        total += target.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(trainloader.dataset)\n",
        "    train_acc = 100 * correct / total\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    test_loss, test_acc = evaluate(model, testloader, loss_fn)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    wandb.log({\"epoch\": epoch, \"train_loss\": avg_loss, \"train_accuracy\": train_acc, \"test_loss\": test_loss, \"test_accuracy\": test_acc})\n",
        "\n",
        "    print(f\"Epoch {epoch}: \"f\"Train Loss={avg_loss:.4f}, \"f\"Train Acc={train_acc:.2f}%, \"f\"Test Loss={test_loss:.4f}, \"f\"Test Acc={test_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY8hw4Vsvdax",
        "outputId": "63223476-b53c-4104-e72e-e711c25caed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss=0.9269, Train Acc=81.90%, Test Loss=0.9320, Test Acc=81.59%\n",
            "Epoch 1: Train Loss=0.7721, Train Acc=88.93%, Test Loss=0.7583, Test Acc=88.53%\n",
            "Epoch 2: Train Loss=0.7331, Train Acc=90.59%, Test Loss=0.7664, Test Acc=87.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Visualize some test images with predictions\n",
        "data_iter = iter(testloader)\n",
        "images, labels = next(data_iter)\n",
        "outputs = model(images)\n",
        "_, preds = torch.max(outputs, 1)\n",
        "\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "for idx in range(8):\n",
        "    ax = fig.add_subplot(2,4,idx+1)\n",
        "    ax.imshow(images[idx].cpu().squeeze(), cmap='gray')\n",
        "    ax.set_title(f\"Pred: {preds[idx].item()}\\nTrue: {labels[idx].item()}\")\n",
        "    ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Finish W&B run\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "jNzF9hzZvfzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_range = range(1, len(train_losses) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs_range, train_losses, marker='o', label=\"Train Loss\")\n",
        "plt.plot(epochs_range, test_losses, marker='o', label=\"Test Loss\")\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train vs Test Loss (MiniResNet + ResBound)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Xtl1T7tRxAGZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}